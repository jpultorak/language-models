{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-17T12:50:55.620547Z",
     "start_time": "2026-01-17T12:50:55.615756Z"
    }
   },
   "source": [
    "from typing import List\n",
    "from transformers import LlamaTokenizerFast\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children: dict[int, TrieNode] = {}\n",
    "        self.is_leaf = False\n",
    "\n",
    "class TokenTrie:\n",
    "    def __init__(self, tokenizer: LlamaTokenizerFast):\n",
    "        self.root = TrieNode()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def init_from_words(self, words: List[str]):\n",
    "        for word in words:\n",
    "            self.insert_word(\" \" + word)\n",
    "\n",
    "    def insert_word(self, word: str):\n",
    "        tokens = self.tokenizer.encode(word, add_special_tokens=False)\n",
    "        tokens.append(self.tokenizer.eos_token_id)\n",
    "        self._insert_tokens(tokens)\n",
    "\n",
    "    def walk(self, token_ids: List[int]):\n",
    "        cur = self.root\n",
    "        for id in token_ids:\n",
    "            if id not in cur.children:\n",
    "                return None\n",
    "            cur = cur.children[id]\n",
    "        return cur\n",
    "\n",
    "    def _insert_tokens(self, token_ids: List[int]):\n",
    "        cur = self.root\n",
    "        for id in token_ids:\n",
    "            if id not in cur.children:\n",
    "                cur.children[id] = TrieNode()\n",
    "            cur = cur.children[id]\n",
    "        cur.is_leaf = True"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:21:30.880890Z",
     "start_time": "2026-01-17T12:21:30.874032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import LogitsProcessor\n",
    "import torch\n",
    "class TrieLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, trie: TokenTrie, prompt_len: int):\n",
    "        self.trie = trie\n",
    "        self.prompt_len = prompt_len\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        masked_scores = torch.full_like(scores, -float(\"inf\"))\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            generated_tokens = input_ids[i, self.prompt_len:].tolist()\n",
    "            cur_node = self.trie.walk(generated_tokens)\n",
    "            if not cur_node or not cur_node.children:\n",
    "                allowed_tokens = [self.trie.tokenizer.eos_token_id]\n",
    "            else:\n",
    "                allowed_tokens = list(cur_node.children.keys())\n",
    "            masked_scores[i, allowed_tokens] = scores[i, allowed_tokens]\n",
    "\n",
    "        return masked_scores"
   ],
   "id": "712df17dea032e19",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:07:34.647481Z",
     "start_time": "2026-01-17T12:07:24.559911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"eryk-mazus/polka-1.1b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ],
   "id": "5f594c94a8c7a2f5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:46:20.391659Z",
     "start_time": "2026-01-17T12:46:20.383879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_answers(question, trie, K):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    prompt_len = input_ids.shape[1]\n",
    "    processor = TrieLogitsProcessor(trie, prompt_len=prompt_len)\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=15,\n",
    "        logits_processor=[processor],\n",
    "        num_beams=K,\n",
    "        num_return_sequences=K,\n",
    "        top_k=50,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    decoded_answers = []\n",
    "    seen = set()\n",
    "    for output in outputs:\n",
    "        generated_ids = output[prompt_len:]\n",
    "        text = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        if text not in seen:\n",
    "            decoded_answers.append(text)\n",
    "            seen.add(text)\n",
    "\n",
    "    return decoded_answers\n"
   ],
   "id": "7ed41fb6ed070600",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:46:32.341453Z",
     "start_time": "2026-01-17T12:46:29.746308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "allowed_words = [\"Krak√≥w\", \"Warszawa\", \"Londyn\", \"Stachu\", \"Opole\", \"Alutek\", \"Wawel\", \"Wie≈ºa Eiffela\", \"Monke\"]\n",
    "trie = TokenTrie(tokenizer=tokenizer)\n",
    "trie.init_from_words(allowed_words)\n",
    "\n",
    "test_question = \"Nazwa s≈Çynnego zamku w Krakowie:\"\n",
    "\n",
    "ans = generate_answers(test_question, trie, K=7)\n",
    "print(ans)"
   ],
   "id": "e058c002e7bbdef8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wawel', 'Krak√≥w', 'Stachu', 'Opole', 'Londyn']\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Riddles dataset and evaluation",
   "id": "b483eef61d585630"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:46:39.348574Z",
     "start_time": "2026-01-17T12:46:37.756533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "path_to_data = '../../datasets/riddles'\n",
    "\n",
    "bases = {}\n",
    "allowed_words_set = set()\n",
    "allowed_words = []\n",
    "answers = []\n",
    "queries = []\n",
    "\n",
    "def get_word_base(word):\n",
    "    global bases\n",
    "    word = word.lower()\n",
    "    ret = bases.get(word)\n",
    "    if ret:\n",
    "        return ret\n",
    "    return word\n",
    "\n",
    "for x in open(f'{path_to_data}/superbazy_clean.txt'):\n",
    "    word,base = x.lower().split()\n",
    "    bases[word] = base\n",
    "\n",
    "print(\"Loading allowed vocabulary...\")\n",
    "with open(f'{path_to_data}/plwiktionary_definitions_clean.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('###')\n",
    "        word = parts[0].strip()\n",
    "        if ' ' not in word:\n",
    "            allowed_words_set.add(word)\n",
    "\n",
    "allowed_words = list(allowed_words_set)\n",
    "print(f\"Loaded {len(allowed_words)} unique allowed words.\")\n",
    "\n",
    "with open(f'{path_to_data}/zagadki_do_testow_clean.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.replace(';;', '').split()\n",
    "        answers.append(line[0])\n",
    "        queries.append(' '.join(line[1:]))"
   ],
   "id": "5d4b72de0ec608f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading allowed vocabulary...\n",
      "Loaded 8085 unique allowed words.\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:46:40.285275Z",
     "start_time": "2026-01-17T12:46:40.282601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mean_reciprocal_rank(real_answers, computed_answers, K=20):\n",
    "    positions = []\n",
    "\n",
    "    for real_answer, computed_answer in zip(real_answers, computed_answers):\n",
    "        if real_answer in computed_answer[:K]:\n",
    "            pos = computed_answer.index(real_answer) + 1\n",
    "            positions.append(1 / pos)\n",
    "\n",
    "    mrr = sum(positions) / len(real_answers)\n",
    "    print('Mean Reciprocal Rank =', mrr)\n",
    "\n",
    "    return mrr\n",
    "\n",
    "def evaluate_algorithm(score_function, queries, answers, K):\n",
    "    computed_answers = []\n",
    "    for query in tqdm(queries, desc=\"queries answered\"):\n",
    "        computed_answers.append(score_function(query, K=K))\n",
    "    score = mean_reciprocal_rank(answers, computed_answers, K=K)\n",
    "\n",
    "    return score"
   ],
   "id": "1c3525a52c584a33",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:53:51.733208Z",
     "start_time": "2026-01-17T12:53:51.610381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Creating trie from {len(allowed_words)} words\")\n",
    "trie = TokenTrie(tokenizer=tokenizer)\n",
    "trie.init_from_words(allowed_words)\n",
    "print(f\"Done\")"
   ],
   "id": "291c85b3f7fda825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trie from 8085 words\n",
      "Done\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T12:53:55.674955Z",
     "start_time": "2026-01-17T12:53:55.672970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def answer_riddle(riddle, K):\n",
    "    prompt = f\"Zagadka: {riddle}\\nOdpowied≈∫:\"\n",
    "    return generate_answers(prompt, trie, K)"
   ],
   "id": "8b8ff27911092eb7",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T13:00:12.542461Z",
     "start_time": "2026-01-17T13:00:09.173333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "i = random.randint(0, len(queries) - 1)\n",
    "\n",
    "sample_query = queries[i]\n",
    "sample_answer = answers[i]\n",
    "\n",
    "print(f\"üîç TESTING RIDDLE INDEX {i}\")\n",
    "print(f\"‚ùì Prompt: '{sample_query}'\")\n",
    "print(f\"üéØ Real Answer: '{sample_answer}'\")\n",
    "\n",
    "# Run the model\n",
    "# Make sure your answer_riddle function handles formatting the prompt!\n",
    "# If not, do: preds = answer_riddle(f\"{sample_query} Odpowied≈∫:\", K=20)\n",
    "preds = answer_riddle(sample_query, K=20)\n",
    "\n",
    "print(f\"\\nü§ñ Model Predictions (Top {len(preds)}):\")\n",
    "print(preds)\n",
    "\n",
    "# Check correctness\n",
    "if sample_answer in preds:\n",
    "    rank = preds.index(sample_answer) + 1\n",
    "    print(f\"\\n‚úÖ SUCCESS! Found at rank #{rank}\")\n",
    "    print(f\"   Score contribution: {1/rank:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå FAILURE. Correct answer not found.\")"
   ],
   "id": "da878c1bf7f90720",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TESTING RIDDLE INDEX 229\n",
      "‚ùì Prompt: 'narzƒôdzie lub przedmiot noszony na twarzy lub g≈Çowie, s≈Çu≈ºƒÖcy do zas≈Çaniania lub ochrony, czƒôsto stosowany w celach higienicznych, medycznych, dekoracyjnych lub w celach ochrony przed szkodliwymi substancjami.'\n",
      "üéØ Real Answer: 'maska'\n",
      "\n",
      "ü§ñ Model Predictions (Top 20):\n",
      "['bi≈ºuteria', 'higiena', 'narzƒôdzie', 'zabawka', 'zagadka', 'przyprawa', 'artykulacja', 'maseczka', 'zab√≥jca', 'przypadek', 'zab√≥jstwo', 'gƒÖbka', 'medycyna', 'obuwie', 'skarbnik', 'zabieganie', 'plastik', 'gumka', 'zamek', 'zabieg']\n",
      "\n",
      "‚ùå FAILURE. Correct answer not found.\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T13:00:08.199464Z",
     "start_time": "2026-01-17T12:55:44.062626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PART_OF_DATA = 100\n",
    "K = 20\n",
    "valid_queries = queries[:PART_OF_DATA]\n",
    "valid_answers = answers[:PART_OF_DATA]\n",
    "score = evaluate_algorithm(answer_riddle, valid_queries, valid_answers, K=K)\n",
    "print(f\"Score: {score}\")"
   ],
   "id": "a6610417ee491ecd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "queries answered:   0%|          | 0/100 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "queries answered: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [04:24<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank = 0.0645901686033265\n",
      "Score: 0.0645901686033265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d84f85b7818fc9e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
